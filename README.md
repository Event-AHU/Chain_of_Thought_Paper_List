# Chain of Thought Paper List 



<p align="center">
<img src="https://github.com/Event-AHU/Chain_of_Thought_Paper_List/blob/main/CoT_figure.png" width="800">
</p>


### Survey and Review 


* Marjanović, Sara Vera, et al. "**DeepSeek-R1 Thoughtology: Let's< think> about LLM Reasoning.**" arXiv preprint arXiv:2504.07128 (2025).
  [[Paper](https://arxiv.org/pdf/2504.07128)] 

* Chu, Zheng, et al. "**Navigate through enigmatic labyrinth a survey of chain of thought reasoning: Advances, frontiers and future.**" Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2024.
  [[Paper](https://aclanthology.org/2024.acl-long.65/)]
  [[Code](https://github.com/zchuz/CoT-Reasoning-Survey)]

* **Logical Reasoning in Large Language Models: A Survey**,
  Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, Yue Zhang
  [[Paper](https://arxiv.org/abs/2502.09100)]

* **From System 1 to System 2: A Survey of Reasoning Large Language Models**,
  Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhijiang Guo, Le Song, Cheng-Lin Liu
  [[Paper](https://arxiv.org/abs/2502.17419)]

* **Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models**，
  Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, Wanxiang Che
  [[Paper](https://arxiv.org/abs/2503.09567)]
  [[Code](https://long-cot.github.io/)] 

* Wang G, Zhang S, Zhan T, et al. **Unlocking the Mysteries of OpenAI o1: A Survey of the Reasoning Abilities of Large Language Models**[J].
  [[Paper](https://openreview.net/pdf?id=J0ADLa2rNp)]

* **Multimodal Chain-of-Thought Reasoning: A Comprehensive Survey**,
  Yaoting Wang, Shengqiong Wu, Yuecheng Zhang, William Wang, Ziwei Liu, Jiebo Luo, Hao Fei
  [[Paper](https://arxiv.org/abs/2503.12605)]
  [[Github](https://github.com/yaotingwangofficial/Awesome-MCoT)] 
  

### Video Tutorial 

* **Chain of Thought论文、代码和资源【论文精读】** [[Youtube-跟李沐学AI](https://youtu.be/H4J59iG3t5o?si=Fina_36yW49O5r_Z)]

* 


### Source Code 






### Year 2025 


* [arXiv:2505.14362] **DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning**,
  Ziwei Zheng, Michael Yang, Jack Hong, Chenxiao Zhao, Guohai Xu, Le Yang, Chao Shen, Xing Yu
  [[Paper](https://arxiv.org/abs/2505.14362)]
  
* **Visionary-R1: Mitigating Shortcuts in Visual Reasoning with Reinforcement Learning**,
  Jiaer Xia, Yuhang Zang, Peng Gao, Yixuan Li, Kaiyang Zhou
  [[Paper](https://arxiv.org/abs/2505.14677)]
   
* **ChestX-Reasoner: Advancing Radiology Foundation Models with Reasoning through Step-by-Step Verification**,
  Ziqing Fan, Cheng Liang, Chaoyi Wu, Ya Zhang, Yanfeng Wang, Weidi Xie
  [[Paper](https://arxiv.org/abs/2504.20930)]
  [[Code](https://github.com/LiangChengBupt/ChesX-Reasoner)]
  
* **T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT**
  [[Paper](https://arxiv.org/pdf/2505.00703)]
  [[Code](https://github.com/CaraJ7/T2I-R1)] 
   
* **Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning**,
  Bowen Jin, Hansi Zeng, Zhenrui Yue, Dong Wang, Hamed Zamani, Jiawei Han
  [[Paper](https://arxiv.org/abs/2503.09516)] 
  
* **S2R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning**，
  Ruotian Ma, Peisong Wang, Cheng Liu, Xingyan Liu, Jiaqi Chen, Bang Zhang, Xin Zhou, Nan Du, Jia Li
  [[Paper](https://www.arxiv.org/abs/2502.12853)]
  [[Code](https://github.com/NineAbyss/S2R)]
  
* **LLaVA-CoT: Let Vision Language Models Reason Step-by-Step**,
  Guowei Xu, Peng Jin, Hao Li, Yibing Song, Lichao Sun, Li Yuan
  [[Paper](https://arxiv.org/abs/2411.10440v2)]
  [[Code](https://github.com/PKU-YuanGroup/LLaVA-CoT)]
  
* **A Comparison of DeepSeek and Other LLMs**,
  Tianchen Gao, Jiashun Jin, Zheng Tracy Ke, Gabriel Moryoussef
  [[Paper](https://arxiv.org/abs/2502.03688)]
  
* **JingFang: A Traditional Chinese Medicine Large Language Model of Expert-Level Medical Diagnosis and Syndrome Differentiation-Based Treatment**,
  Yehan Yan, Tianhao Ma, Ruotai Li, Xinhan Zheng, Guodong Shan, Chisheng Li
  [[Paper](https://arxiv.org/abs/2502.04345)] 
  
* **Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization**,
  Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu
  [[Paper](https://arxiv.org/abs/2502.04667)]
  [[Code](https://github.com/chen123CtrlS/TCotMechanism)]
  
* **Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**,
  Junde Wu, Jiayuan Zhu, Yuyuan Liu
  [[Paper](https://arxiv.org/abs/2502.04644)]
  
* **Fino1: On the Transferability of Reasoning Enhanced LLMs to Finance**,
  Lingfei Qian, Weipeng Zhou, Yan Wang, Xueqing Peng, Jimin Huang, Qianqian Xie
  [[Paper](https://arxiv.org/abs/2502.08127)] 
  [[Code](https://github.com/The-FinAI/Fino1)] 
  
* **LawGPT: Knowledge-Guided Data Generation and Its Application to Legal LLM**, 
  Zhi Zhou, Kun-Yang Yu, Shi-Yu Tian, Xiao-Wen Yang, Jiang-Xin Shi, Pengxiao Song, Yi-Xuan Jin, Lan-Zhe Guo, Yu-Feng Li
  [[Paper](https://arxiv.org/abs/2502.06572)]
  [[Code](https://github.com/LAMDASZ-ML/Knowledge-Guide-Data-Generation)]
  
* **On the Emergence of Thinking in LLMs I: Searching for the Right Intuition**,
  Guanghao Ye, Khiem Duc Pham, Xinzhi Zhang, Sivakanth Gopi, Baolin Peng, Beibin Li, Janardhan Kulkarni, Huseyin A. Inan
  [[Paper](https://arxiv.org/abs/2502.06773)]
  [[Code](https://github.com/GuanghaoYe/Emergence-of-Thinking)] 
  
* **ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates**,
  Ling Yang, Zhaochen Yu, Bin Cui, Mengdi Wang
  [[Paper](https://arxiv.org/abs/2502.06772)]
  [[Code](https://github.com/Gen-Verse/ReasonFlux)]
  
* **Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**, 
  Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha
  [[Paper](https://arxiv.org/abs/2502.05078)]
  
* **CoT-Valve: Length-Compressible Chain-of-Thought Tuning**, 
  Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang
  [[Paper](https://arxiv.org/abs/2502.09601)]
  [[Code](https://github.com/horseee/CoT-Valve)] 
  
* **MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency**, 
  Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li
  [[Paper](https://arxiv.org/abs/2502.09621)]
  [[Project Page](https://mmecot.github.io/)] 
  
* [arXiv:2502.06428] **CoS: Chain-of-Shot Prompting for Long Video Understanding**, 
  Jian Hu, Zixu Cheng, Chenyang Si, Wei Li, Shaogang Gong
  [[Paper](https://arxiv.org/abs/2502.06428)]
  
* **Can We Generate Images with CoT? Let’s Verify and Reinforce Image Generation Step by Step**,
  ZiyuGuo∗1,RenruiZhang∗†2,ChengzhuoTong∗4,ZhizhengZhao∗3 PengGao4,HongshengLi‡2,Pheng-AnnHeng‡ 
  [[Paper](https://arxiv.org/pdf/2501.13926)]
  [[Code](https://github.com/ZiyuGuo99/Image-Generation-CoT)] 
  
* Liu, Yuecheng, et al. "**SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and Chain-of-Thought for Embodied Task Planning.**"
  arXiv preprint arXiv:2501.10074 (2025).
  [[Paper](https://arxiv.org/pdf/2501.10074)]
  
* Thawakar, Omkar, et al. "**LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs.**" arXiv preprint arXiv:2501.06186 (2025).
  [[Paper](https://arxiv.org/abs/2501.06186)]
  





  
### Year 2024 

* [arXiv:2412.06769] **Training Large Language Models to Reason in a Continuous Latent Space**, 
  Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian
  [[Paper](https://arxiv.org/abs/2412.06769)]

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [[Paper]()] 

* [AAAI 2024] **T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Mixed Large Language Model Signals for Science Question Answering**
  Lei Wang, Yi Hu, Jiabang He, Xing Xu, Ning Liu, Hui Liu, Heng Tao Shen
  [[Paper](https://arxiv.org/abs/2305.03453)]
  [[Code](https://github.com/T-SciQ/T-SciQ)]

* [ECCV 2024] **Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training**
  Cheng Tan, Jingxuan Wei, Zhangyang Gao, Linzhuang Sun, Siyuan Li, Ruifeng Guo, Bihui Yu, Stan Z. Li
  [[Paper](https://arxiv.org/abs/2311.14109)]
  [[Code](https://github.com/chengtan9907/mc-cot)]

* **KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning**
  Debjyoti Mondal, Suraj Modi, Subhadarshi Panda, Rituraj Singh, Godawari Sudhakar Rao
  [[Paper](https://arxiv.org/abs/2401.12863)] 


* **Uncovering Latent Chain of Thought Vectors in Language Models**,
  Jason Zhang, Scott Viteri
  [[Paper](https://arxiv.org/abs/2409.14026)] 

* **Exploring Defeasible Reasoning in Large Language Models: A Chain-of-Thought Approach**,
  Zhaoqun Lia, Chen Chena and Beishui Liaoa,
  [[Paper](https://collegepublications.co.uk/downloads/LNGAI00004.pdf#page=136)] 

* **MasonTigers at SemEval-2024 Task 9: Solving Puzzles with an Ensemble of Chain-of-Thoughts**, 
  Md Nishat Raihan, Dhiman Goswami, Al Nahian Bin Emran, Sadiya Sayara Chowdhury Puspo, Amrita Ganguly, Marcos Zampieri
  [[Paper](https://arxiv.org/abs/2403.14982)] 

* **NLPeople at TextGraphs-17 Shared Task: Chain of Thought Questioning to Elicit Decompositional Reasoning**,
  Movina Moses, Vishnudev Kuruvanthodi, Mohab Elkaref, Shinnosuke Tanaka, James Barry, Geeth Mel, Campbell Watson
  [[Paper](https://aclanthology.org/2024.textgraphs-1.13.pdf)]  

* K. Hu et al., "**Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection,**" 2024 International Joint Conference on Neural Networks (IJCNN), Yokohama, Japan, 2024, pp. 1-8, doi: 10.1109/IJCNN60899.2024.10650428.
  [[Paper](https://ieeexplore.ieee.org/abstract/document/10650428)] 

* **Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models**,
  Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych
  [[Paper](https://openreview.net/forum?id=u4whlT6xKO)] 
  
* **HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs**,
  Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu, Rongsheng Wang, Jianye Hou, Benyou Wang
  [[Paper](https://arxiv.org/abs/2412.18925)]
  [[Code](https://github.com/FreedomIntelligence/HuatuoGPT-o1)]
  [[Wechat Blog](https://mp.weixin.qq.com/s/IO8k4VEuq9SuIQy71yoZ_g)] 

* Feng, Guhao, et al. "**Towards revealing the mystery behind chain of thought: a theoretical perspective.**"
  Advances in Neural Information Processing Systems 36 (2024).
  [[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/dfc310e81992d2e4cedc09ac47eff13e-Abstract-Conference.html)]

* He, Liqi, et al. "**Multi-modal latent space learning for chain-of-thought reasoning in language models.**"
  Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 38. No. 16. 2024.
  [[Paper](http://arxiv.org/abs/2312.08762)]
  [[Code]](https://github.com/shimurenhlq/DPMM-COT)

* Yin, Han, et al. "**Answering Spatial Commonsense Questions Based on Chain-of-Thought Reasoning with Adaptive Complexity.**" Asia-Pacific Web (APWeb) and Web-Age Information Management (WAIM) Joint International Conference on Web and Big Data. Singapore: Springer Nature Singapore, 2024.
  [[Paper](https://link.springer.com/chapter/10.1007/978-981-97-7232-2_13)]

* Hu, H., Lu, H., Zhang, H., Song, Y. Z., Lam, W., & Zhang, Y. **Chain-of-Symbol Prompting for Spatial Relationships in Large Language Models**. COLM 2024 
  [[Paper](https://openreview.net/pdf?id=Hvq9RtSoHG)]
  [[Code](https://github.com/hanxuhu/chain-of-symbol-planning)]



### Year 2023 

* **Multimodal Chain-of-Thought Reasoning in Language Models**.
  Zhang, Z.; Zhang, A.; Li, M.; Zhao, H.; Karypis, G.; and Smola.
  [[Paper](https://arxiv.org/abs/2302.00923)]
  [[Code]](https://github.com/amazon-science/mm-cot)
  
* Wang, Keheng, et al. "**Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-intensive question answering.**"
  arXiv preprint arXiv:2308.13259 (2023).
  [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/29776)]

* [ICLR 2023]**Self-Consistency Improves Chain of Thought Reasoning in Language Models**
  Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou
  [[Paper](https://arxiv.org/abs/2203.11171)]

### Year 2022

* **Automatic Chain of Thought Prompting in Large Language Models**
  Zhuosheng Zhang, Aston Zhang, Mu Li, Alex Smola
  [[Paper](https://arxiv.org/abs/2210.03493)]

* [NeurIPS 2022]**Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering**
  Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, Ashwin Kalyan
  [[Paper](https://arxiv.org/abs/2209.09513)]
  [[Code](https://github.com/lupantech/ScienceQA?tab=readme-ov-file)]
  [[Leaderboard](https://scienceqa.github.io/leaderboard.html)]

* **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**
  Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou
  [[Paper](https://arxiv.org/abs/2201.11903)]

  
